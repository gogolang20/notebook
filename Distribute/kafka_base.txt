# Kafka入门

## 第一章

### Kafka概述、介绍
应用场景:
异步通信
系统间解耦
数据的削峰填谷


### 架构和概念
```
消息队列:分布式和大数据开发中不可或缺的中间件

Kafka 数据消费没有限制 可以配置消息保持时间

Kafka集群 以Topic形式负责分类集群中的Record,每个Record属于一个Topic
每个Topic底层会对应一组分区的日志用于持久化 Topic的 Record。Topic是一个逻辑概念

每个分区都一定有一个Borker担当该分区的Leader,其他Borker担当该分区的follower
Leader负责读写,follower负责同步该分区的数据。

Record:key + value + timestamp
默认消息分发策略:Hash[key]%分区数 #相同 key的数据落入同一分区 

分区(Partition):一个Topic数据分散存储到不同文件
分区因子:每个分区文件在集群中备份数量

--replication-factor 分区因子(备份数,不可以大于节点数)
```



### 分区&日志

```
分区 Partition 每组日志分区时一个有序的不可变的日志序列
分区之间的数据写入顺序是无法保证的

Kafka中Recode信息默认保存168小时,配置文件中可以修改
日志存储到磁盘上
```



### 生产者&消费组
消费者消费数据,会记录对应的offset,并提交给Kafka集群

消费者和消费组
消费组可以实现容错性和可伸缩性
消费组成员一般不会超过Topic的分区数


### 顺序写入&ZeroCopy
如何保持高吞吐率
顺序写入 && MMFile (内存映射文件 Memory Mapped Files)
顺序I/O, 减少磁盘寻址时间和内存开销
Kafka的数据并不是实时写入硬盘中
磁盘空间映射到内核空间
pagecache 等待系统刷新数据到磁盘,提高了写入I/O

响应客户端消费数据
ZeroCopy:直接将数据通过内核空间传递输出,无需拷贝到用户空间

DMA:Direct Memory Access 协处理器 减少了cpu中断次数 
read系统调用-->CPU-->DMA-->磁盘-->DMA-->CPU
可以将CPU解放出来,读取完成后再回头处理


## 第二章

### zookeeper和Kafka 安装&&集群搭建
### Kafka Topic管理
```
副本因子数量不可以超过 Borker 数量
分区数只能增,不能减
--alter 修改Kafka分区数
--delete 删除Kafka分区
```


## 第四章

### offset自动控制
```
auto.offset.reset=latest
earliest
latest
none

offset 自动提交
enable.auto.commit=true
auto.commit.interval.ms=5000 #默认5秒
```



### Ackes&Retires
```
Kafka生产者发送完一条消息后,要求Broker在规定的时间Ack应答,如果没有再规定时间内应答,Kafka生产者会尝试n次重新发送消息

确保数据的可靠传输
acks=1 #默认 
Leader不会等待所有Follower完全确认的情况下再做出响应,会存在写丢失

acks=-1 #需要等待全套副本确认记录,至少一个follower备份成功

重试发送(可能造成消息重复发送)
request.timeout.ms=3000 #默认3秒
```



### 幂等写
```
幂等是针对生产者角度的特性,可以保证生产者发送的消息不会丢失,不会重复

实现幂等关键需要服务端可以区分请求是否重复,过滤掉重复的请求。
如何区分请求是否重复？？？
1 唯一标识:例如订单号等
2 记录下已处理过的请求标识

幂等又称 exactly one

enable.idempotence=false #默认关闭  开启是true
注意:使用幂等性的时候,要求必须开启 retries=true 和 acks=-1
```


### 生产者事务
```
Kafka幂等性,只能保证一条记录在分区发送的原子性,如何保证多个分区之间的完整性,需要开启Kafka的事务操作

生产者事务Only
消费者&生产者事务

在开启生产者事务之后,需要用户设置消费者的事务隔离级别
isolation.level= read_uncommitted #默认  修改成read_committed

配置事务ID transaction.id
```

### 生产者&消费者
```
应用场景较多
消费者&生产者事务 必须关闭消费者端的 offset 自动提交
```


## 第五章

### 高水位

```
Kafka数据同步机制
分区时按segments存储文件块,默认大小1G
0.11版本之前使用 high watermark机制同步数据
high watermark 同步数据可能导致数据的不一致或者是乱序
log end offset:表示每个分区中最后一条消息的下一个位置

high watermark 所有HW之前的数据都理解是已经备份的,当所有节点都备份成功,Leader会更新水位线

ISR In-sync-replicas::Kafka会维护一份处于同步的副本集合
基于时间的副本剔除策略

Kafka 0.11版本之前  HW会导致 数据丢失和数据不一致 !!!
```

```
Leader epoch:leader迭代 作为消息截断的参考点
一个32为数字,存储在zookeeper分区状态信息中
```
